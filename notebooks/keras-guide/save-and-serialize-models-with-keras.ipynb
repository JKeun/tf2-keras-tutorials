{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this guide covers saving and serialization for Keras models built using the Functional and Sequential APIs. Saving and serialization is exactly same for both of these model APIs.\n",
    "\n",
    "The second part of this guide covers \"saving and loading subclassed models\". The subclassing API differs from the Keras sequential and functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Saving Sequential models or Functional models\n",
    "Let's consider the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3_layer_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(10, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, let's train this model, just so it has weight values to save, as well as an optimizer state. Of course, you can save models you've never trained, too, but obviously that's less interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3108\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)\n",
    "# Reset metrics before saving so that loaded model has same state.\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole-model saving\n",
    "You can save a model built with the Functional APi into a single file. You can later recreate the same model from this file, even if you no longer have access to the code that created the model.\n",
    "\n",
    "This file includes:\n",
    "- The model's architecture\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's training config (what you passed to `compile`), if any\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to SavedModel\n",
    "You can also export a whole model to the TensorFlow `SavedModel` format. `SavedModel` is a standalone serialization format for TensorFlow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jkpark/.pyenv/versions/3.7.1/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: path_to_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "model.save('path_to_saved_model', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.models.load_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_saved_model/:\r\n",
      "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\r\n",
      "\r\n",
      "path_to_saved_model/assets:\r\n",
      "\r\n",
      "path_to_saved_model/variables:\r\n",
      "variables.data-00000-of-00002  variables.data-00001-of-00002  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "ls -R 'path_to_saved_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SavedModel` files that were created contain:\n",
    "- A TensorFlow checkpoint containing the model weights.\n",
    "- A `SavedModel` proto containing the underlying TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture-only saving\n",
    "Sometimes, you are only interested in the architecture of the model, and you don't need to save the weight values or the optimizer. In this case, you can retrieve the \"config\" of the model via the `get_config()` method. The config is a Python dict that enables you to recreate the same model -- initialized from scratch, without any of the information learned previously during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "reinitialized_model = keras.Model.from_config(config)\n",
    "\n",
    "# Note that the model state is not preserved! We only saved the architecture.\n",
    "new_predictions = reinitialized_model.predict(x_test)\n",
    "assert abs(np.sum(predictions - new_predictions)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively use `to_json()` from `from_json()`, which uses a JSON string to store the config instead of a Python dict. This is useful to save the config to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_config = model.to_json()\n",
    "reinitialized_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights-only saving\n",
    "Sometimes, you are only interested in the state of the model -- its weights values -- and not in the architecture. In this case, you can retrieve the weights values as a list of Numpy arrays via `get_weights()`, and set the state of the model via `set_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()  # Retrieves the state of the model.\n",
    "model.set_weights(weights)  # Sets the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine `get_config()` / `from_config()` and `get_weights()` / `set_weights()` to recreate your model in the same state. However, unlike `model.save()`, this will not include the training config and the optimizer. You would have to call `compile()` again before using the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "weight = model.get_weights()\n",
    "\n",
    "new_model = keras.Model.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer was not preserved,\n",
    "# so the model should be compiled a new before training\n",
    "# (and the optimizer will start from a blank state)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save-to-disk alternative to `get_weights()` and `set_weights(weights)` is `save_weights(fpath)` and `load_weights(fpath)`.\n",
    "\n",
    "Here's an example that saves to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON config to disk\n",
    "json_config = model.to_json()\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "model.save_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Reload the model from the 2 files we saved\n",
    "with open('model_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "new_model = keras.models.model_from_json(json_config)\n",
    "new_model.load_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer was not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember that the simplest, recommended way is jsut this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "del model\n",
    "model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights-only saving using TensorFlow checkpoints\n",
    "Note that `save_weights` can create files either in the Keras HDF5 format, or in the `TensorFlow Checkpoint` format. The format is inferred from the file extension you provide: if it is \".h5\" or \".keras\", the framework uses the Keras HDF5 format. Anything else defaults to Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "keras-overview.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;35mmini_resnet.png\u001b[0m\r\n",
      "model_config.json\r\n",
      "\u001b[01;35mmulti_input_and_output_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model_with_shape_info.png\u001b[0m\r\n",
      "\u001b[01;34mmymodel_1\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_2\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_3\u001b[0m/\r\n",
      "my_model.h5\r\n",
      "path_to_my_model.h5\r\n",
      "path_to_my_tf_checkpoint.data-00000-of-00002\r\n",
      "path_to_my_tf_checkpoint.data-00001-of-00002\r\n",
      "path_to_my_tf_checkpoint.index\r\n",
      "path_to_my_weights.h5\r\n",
      "\u001b[01;34mpath_to_saved_model\u001b[0m/\r\n",
      "save-and-serialize-models-with-keras.ipynb\r\n",
      "the-keras-functional-API-in-Tensorflow.ipynb\r\n",
      "train-and-evalutate-with-Keras.ipynb\r\n",
      "\u001b[01;34mweights\u001b[0m/\r\n",
      "writing-custom-layers-and-models-with-keras.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For total expliciteness, the format can be explicitly passed via the `save_format` argument, which can take the value \"tf\" or \"h5\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_checkpoint', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "keras-overview.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;35mmini_resnet.png\u001b[0m\r\n",
      "model_config.json\r\n",
      "\u001b[01;35mmulti_input_and_output_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model_with_shape_info.png\u001b[0m\r\n",
      "\u001b[01;34mmymodel_1\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_2\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_3\u001b[0m/\r\n",
      "my_model.h5\r\n",
      "path_to_my_model.h5\r\n",
      "path_to_my_tf_checkpoint.data-00000-of-00002\r\n",
      "path_to_my_tf_checkpoint.data-00001-of-00002\r\n",
      "path_to_my_tf_checkpoint.index\r\n",
      "path_to_my_weights.h5\r\n",
      "\u001b[01;34mpath_to_saved_model\u001b[0m/\r\n",
      "save-and-serialize-models-with-keras.ipynb\r\n",
      "the-keras-functional-API-in-Tensorflow.ipynb\r\n",
      "train-and-evalutate-with-Keras.ipynb\r\n",
      "\u001b[01;34mweights\u001b[0m/\r\n",
      "writing-custom-layers-and-models-with-keras.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Saving and Loading of Subclassed Models\n",
    "Sequential models and Functional models are datastructures that represent a DAG of layers. As such, they can be safely serialized and deserialized.\n",
    "\n",
    "A subclassed model differs in that it's not a datastructure, it's a piece of code. The architecture of the model is defined via the body of the call method. This means that the architecture of the model cannot be safely serialized. To load a model, you'll need to have access to the code that created it (the code of the model subclass). Alternatively, you could be serializing this code as bytecode (e.g. via pickling), but that's unsafe and generally not portable.\n",
    "\n",
    "For more information about these differences, see the article [\"What are Symbolic and Imperative APIs in TensorFlow 2.0?\"](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021).\n",
    "\n",
    "Let's consider the following subclassed model, which follows the same structure as the model from the first section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerMLP(keras.Model):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        super(ThreeLayerMLP, self).__init__(name=name)\n",
    "        self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n",
    "        self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\n",
    "        self.pred_layer = layers.Dense(10, name='predictions')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        return self.pred_layer(x)\n",
    "    \n",
    "def get_model():\n",
    "    return ThreeLayerMLP(name='3_layer_mlp')\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, a subclassed model that has never been used cannot be saved.\n",
    "\n",
    "That's because a subclassed model needs to be called on some data in order to create its weights.\n",
    "\n",
    "Until the model has been called, it does not know the shape and dtype of the input data it should be expecting, and thus cannot create its weight variables. You may remember that in the Functional model from the first section, the shape and dtype of the inputs was specified in advance (via `keras.Input(...)`) -- that's why Functional models have a state as soon as they're instantiated.\n",
    "\n",
    "Let's train the model, so as to give it a state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 2.2743\n"
     ]
    }
   ],
   "source": [
    "(x_tarin, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)\n",
    "# Reset metrics before saving so that loaded model has same state.\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three different approaches to save and restore a subclassed model. The following sections provides more details on those three approaches.\n",
    "\n",
    "### Approach 1:\n",
    "The recommended way to save a subclassed model is to use `save_weights` to create a TensorFlow SavedModel checkpoint, which will contain the value of all variables associated with the model:\n",
    "\n",
    "- The layers' weights\n",
    "- The optimizer's state\n",
    "- Any variables associated with stateful model metrics (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)\n",
    "# Also save the loss on the first batch\n",
    "# to later assert that the optimizer state was preserved\n",
    "first_batch_loss = model.train_on_batch(x_train[:64], y_train[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore your model, you will need access to the code that created the model object.\n",
    "\n",
    "Note that in order to restore the optimizer state and the state of any stateful metric, you should compile the model (with the exact same arguments as before) and call it on some data before calling `load_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model\n",
    "new_model = get_model()\n",
    "new_model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "new_model.train_on_batch(x_train[:1], y_train[:1])\n",
    "\n",
    "# Load the state of the old model\n",
    "new_model.load_weights('path_to_my_weights')\n",
    "\n",
    "# Check that the model state has been preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# The optimizer state is preserved as well.\n",
    "# so you can resume training where you left off\n",
    "new_first_batch_loss = new_model.train_on_batch(x_train[:64], y_train[:64])\n",
    "assert first_batch_loss == new_first_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "keras-overview.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;35mmini_resnet.png\u001b[0m\r\n",
      "model_config.json\r\n",
      "\u001b[01;35mmulti_input_and_output_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model_with_shape_info.png\u001b[0m\r\n",
      "\u001b[01;34mmymodel_1\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_2\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_3\u001b[0m/\r\n",
      "my_model.h5\r\n",
      "path_to_my_model.h5\r\n",
      "path_to_my_tf_checkpoint.data-00000-of-00002\r\n",
      "path_to_my_tf_checkpoint.data-00001-of-00002\r\n",
      "path_to_my_tf_checkpoint.index\r\n",
      "path_to_my_weights.data-00000-of-00002\r\n",
      "path_to_my_weights.data-00001-of-00002\r\n",
      "path_to_my_weights.h5\r\n",
      "path_to_my_weights.index\r\n",
      "\u001b[01;34mpath_to_saved_model\u001b[0m/\r\n",
      "save-and-serialize-models-with-keras.ipynb\r\n",
      "the-keras-functional-API-in-Tensorflow.ipynb\r\n",
      "train-and-evalutate-with-Keras.ipynb\r\n",
      "\u001b[01;34mweights\u001b[0m/\r\n",
      "writing-custom-layers-and-models-with-keras.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2:\n",
    "Second approach is by using `model.save` to save whole model and by using `load_model` to restore previously stored subclassed model. The following code snippets describe how to implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "keras-overview.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;35mmini_resnet.png\u001b[0m\r\n",
      "model_config.json\r\n",
      "\u001b[01;35mmulti_input_and_output_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model_with_shape_info.png\u001b[0m\r\n",
      "\u001b[01;34mmymodel_1\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_2\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_3\u001b[0m/\r\n",
      "my_model.h5\r\n",
      "\u001b[01;34mpath_to_my_model\u001b[0m/\r\n",
      "path_to_my_model.h5\r\n",
      "path_to_my_tf_checkpoint.data-00000-of-00002\r\n",
      "path_to_my_tf_checkpoint.data-00001-of-00002\r\n",
      "path_to_my_tf_checkpoint.index\r\n",
      "path_to_my_weights.data-00000-of-00002\r\n",
      "path_to_my_weights.data-00001-of-00002\r\n",
      "path_to_my_weights.h5\r\n",
      "path_to_my_weights.index\r\n",
      "\u001b[01;34mpath_to_saved_model\u001b[0m/\r\n",
      "save-and-serialize-models-with-keras.ipynb\r\n",
      "the-keras-functional-API-in-Tensorflow.ipynb\r\n",
      "train-and-evalutate-with-Keras.ipynb\r\n",
      "\u001b[01;34mweights\u001b[0m/\r\n",
      "writing-custom-layers-and-models-with-keras.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3:\n",
    "Third approach is by using `tf.saved_model.save`. This is equivalent to the `tf` format in `model.save`. You can once again call `load_model` to restore the previously saved subclassed model. The following code snippets describe how to implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "tf.saved_model.save(model, 'my_saved_model')\n",
    "# Restoring the model\n",
    "restored_saved_model = keras.models.load_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "keras-overview.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;35mmini_resnet.png\u001b[0m\r\n",
      "model_config.json\r\n",
      "\u001b[01;35mmulti_input_and_output_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model.png\u001b[0m\r\n",
      "\u001b[01;35mmy_first_model_with_shape_info.png\u001b[0m\r\n",
      "\u001b[01;34mmymodel_1\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_2\u001b[0m/\r\n",
      "\u001b[01;34mmymodel_3\u001b[0m/\r\n",
      "my_model.h5\r\n",
      "\u001b[01;34mmy_saved_model\u001b[0m/\r\n",
      "\u001b[01;34mpath_to_my_model\u001b[0m/\r\n",
      "path_to_my_model.h5\r\n",
      "path_to_my_tf_checkpoint.data-00000-of-00002\r\n",
      "path_to_my_tf_checkpoint.data-00001-of-00002\r\n",
      "path_to_my_tf_checkpoint.index\r\n",
      "path_to_my_weights.data-00000-of-00002\r\n",
      "path_to_my_weights.data-00001-of-00002\r\n",
      "path_to_my_weights.h5\r\n",
      "path_to_my_weights.index\r\n",
      "\u001b[01;34mpath_to_saved_model\u001b[0m/\r\n",
      "save-and-serialize-models-with-keras.ipynb\r\n",
      "the-keras-functional-API-in-Tensorflow.ipynb\r\n",
      "train-and-evalutate-with-Keras.ipynb\r\n",
      "\u001b[01;34mweights\u001b[0m/\r\n",
      "writing-custom-layers-and-models-with-keras.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
